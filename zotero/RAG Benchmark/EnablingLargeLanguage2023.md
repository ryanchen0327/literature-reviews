---
category: literaturenote
tags: Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Information Retrieval
citekey: gaoEnablingLargeLanguage2023
status: unread
dateread:
---
# Notes


Comment: Accepted by EMNLP 2023. Code and data are available at https://github.com/princeton-nlp/ALCE


# Key questions



---
> [!Cite]
> Gao, T., Yen, H., Yu, J., & Chen, D. (2023). _Enabling Large Language Models to Generate Text with Citations_ (No. arXiv:2305.14627). arXiv. [https://doi.org/10.48550/arXiv.2305.14627](https://doi.org/10.48550/arXiv.2305.14627)

> [!Synth]
> **Contribution**::  
>   
> **Related**:: 

> [!Metadata]
> **Authors**::Gao, Tianyu, Yen, Howard, Yu, Jiatong, Chen, Danqi
> **Title**:: Enabling Large Language Models to Generate Text with Citations  
> **Year**:: 2023  
> **Citekey**:: gaoEnablingLargeLanguage2023> **Item Type**:: preprint> **DOI**:: 10.48550/arXiv.2305.14627

> [!Link]
> [Preprint PDF](file:///Users/ryanchen/Zotero/storage/YTQZ3MU2/Gao%20et%20al.%20-%202023%20-%20Enabling%20Large%20Language%20Models%20to%20Generate%20Text%20with%20Citations.pdf)

> [!Abstract]
> Large language models (LLMs) have emerged as a widely-used tool for information seeking, but their generated outputs are prone to hallucination. In this work, our aim is to allow LLMs to generate text with citations, improving their factual correctness and verifiability. Existing work mainly relies on commercial search engines and human evaluation, making it challenging to reproduce and compare different modeling approaches. We propose ALCE, the first benchmark for Automatic LLMs' Citation Evaluation. ALCE collects a diverse set of questions and retrieval corpora and requires building end-to-end systems to retrieve supporting evidence and generate answers with citations. We develop automatic metrics along three dimensions -- fluency, correctness, and citation quality -- and demonstrate their strong correlation with human judgements. Our experiments with state-of-the-art LLMs and novel prompting strategies show that current systems have considerable room for improvement -- For example, on the ELI5 dataset, even the best models lack complete citation support 50% of the time. Our analyses further highlight promising future directions, including developing better retrievers, advancing long-context LLMs, and improving the ability to synthesize information from multiple sources.
---

# Annotations

### Imported: 2025-06-03 2:56 pm




